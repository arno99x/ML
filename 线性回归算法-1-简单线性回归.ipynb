{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性回归算法\n",
    "##### 解决回归问题\n",
    "##### 思想简单，实现容易\n",
    "##### 许多强大的非线性模型的基础\n",
    "##### 结果具有很好的解释性\n",
    "##### 蕴含机器 学习中的很多思想\n",
    "\n",
    "# 简单线性回归\n",
    "##### 样本空间只有一个的回归，叫做简单线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简单线性回归的思路\n",
    "\n",
    "##### 假设我们找到了最佳拟合的直线方程： y = ax+b , 则对于每一个样本点xi (说明：小i应该是在x上方的，只是这里不好编辑） ， 根据我们的直线方程，预测为： axi + b  ,  真值为标签数据yi\n",
    "\n",
    "##### 那么我们希望yi和axi + b的差距尽量的小  ， 差距差使用公式 ：( yi - (axi+b)) **2  来表示\n",
    "##### 把所有的元素与方程式的差值相加， 相加值越小就是方程式追求的结果\n",
    "##### 假设方程式是 ax+b, 那么找到最合适的a和b，使得所有的元素与方程式的差值相加尽可能小\n",
    "###### 备注：度量差值的函数被叫做损失函数（lost function） , 有些函数是度量拟合度的，这种函数又被叫做效用函数（utility function） ，另外误差的平方合也被叫 “最小二乘法”\n",
    "\n",
    "\n",
    "### 为什么要用差值平方呢？\n",
    "##### 因为假设有两个元素  A元素与方程的差值为100， B元素的差值为-100 那么两个元素的差值相加就变成完成拟合了，这显然是不对的\n",
    "##### 用绝对值行不行呢？ 绝对值是不可导的，所以用起来不太方便\n",
    "##### 所以就用了平方\n",
    "\n",
    "### 机器学习思路总结：\n",
    "##### 能过分析问题，确定问题的损失函数或效用函数；\n",
    "##### 通过最优化损失函数或者效用函数，获得机器学习的模型\n",
    "\n",
    "#### 近乎所有的参数学习的算法都是这样的套路，参数学习算法就是要建立模型\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
